{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchinfo\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RotaryPositional Embedding\n",
    "\n",
    "https://nn.labml.ai/transformers/rope/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.rotation_matrix torch.Size([1, 100, 1, 2, 2, 2])\n",
      "y torch.Size([2, 5, 5, 2, 2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RotaryPositionalEmbedding                [2, 5, 5, 4]              --\n",
       "==========================================================================================\n",
       "Total params: 0\n",
       "Trainable params: 0\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RotaryPositionalEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Given a tensor of shape [BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM]\n",
    "    applies Rotary Positional Encoding.\n",
    "    offset allows to apply rotary to sequnce part by part by telling how much tokens preecede the input in the sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimension: int,\n",
    "        max_seq_len: int,\n",
    "        theta: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert dimension % 2 == 0\n",
    "        self.dimension = dimension\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        ## Theta := theta^( -(2i / dimension) ) where i = 0, 1, 2, ..., dimension / 2\n",
    "        self.theta = (\n",
    "            1.0 / (theta ** (torch.arange(0, self.dimension, 2).float() / dimension))\n",
    "        )[None, :]  # [1, dimension / 2]\n",
    "\n",
    "        rot_seq = max_seq_len\n",
    "        m_theta = torch.arange(rot_seq)[:, None].float()  # [max_seq_len, 1]\n",
    "        m_theta = (m_theta @ self.theta)[\n",
    "            :, :, None, None\n",
    "        ]  # [max_seq_len, dimension / 2, 1, 1]\n",
    "\n",
    "        m_sin = m_theta.sin()\n",
    "        m_cos = m_theta.cos()\n",
    "\n",
    "        row0 = torch.cat((m_cos, -m_sin), dim=-1)  # [max_seq_len, dimension / 2, 1, 2]\n",
    "        row1 = torch.cat((m_sin, m_cos), dim=-1)  # [max_seq_len, dimension / 2, 1, 2]\n",
    "\n",
    "        self.rotation_matrix = torch.cat((row0, row1), dim=-2)[None, :, None, :, :, :]\n",
    "        \"\"\"\n",
    "        [1, max_seq_len, 1, dimension / 2, 2, 2]\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x, offset: int = 0):\n",
    "        assert (\n",
    "            len(x.shape) == 4\n",
    "        )  # torch tensor of shape [BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM]\n",
    "        assert offset >= 0\n",
    "\n",
    "        ## reshape\n",
    "        BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM = x.shape\n",
    "        y = x.reshape(BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM // 2, 2, 1)\n",
    "\n",
    "        ## rotate\n",
    "        start, end = offset, offset + SEQ_LEN\n",
    "        print(\"self.rotation_matrix\", self.rotation_matrix.shape)\n",
    "        print(\"y\", y.shape)\n",
    "        y = self.rotation_matrix[:, start:end].to(x.device) @ y\n",
    "\n",
    "        ## reshape\n",
    "        y = y.reshape(BATCH, SEQ_LEN, NUM_HEADS, HEAD_DIM)\n",
    "\n",
    "        assert y.shape == x.shape\n",
    "        return y\n",
    "\n",
    "\n",
    "model = RotaryPositionalEmbedding(dimension=4, max_seq_len=100, theta=10_000)\n",
    "torchinfo.summary(model, input_size=(2, 5, 5, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Term Memory Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k tensor([[[-0.8638, -0.6591, -0.0420,  0.7137, -1.1103]],\n",
      "\n",
      "        [[-0.8638, -0.6591, -0.0420,  0.7137, -1.1103]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9871,  0.7721,  0.2904,  0.1649, -0.4141]],\n",
      "\n",
      "        [[-0.9871,  0.7721,  0.2904,  0.1649, -0.4141]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8638, -0.6590, -0.0420,  0.7138, -1.1104]],\n",
      "\n",
      "        [[-0.8638, -0.6590, -0.0420,  0.7138, -1.1104]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9861,  0.7716,  0.2902,  0.1647, -0.4138]],\n",
      "\n",
      "        [[-0.9861,  0.7716,  0.2902,  0.1647, -0.4138]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8638, -0.6587, -0.0421,  0.7139, -1.1106]],\n",
      "\n",
      "        [[-0.8638, -0.6587, -0.0421,  0.7139, -1.1106]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9841,  0.7707,  0.2898,  0.1644, -0.4134]],\n",
      "\n",
      "        [[-0.9841,  0.7707,  0.2898,  0.1644, -0.4134]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8639, -0.6583, -0.0421,  0.7141, -1.1108]],\n",
      "\n",
      "        [[-0.8639, -0.6583, -0.0421,  0.7141, -1.1108]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9813,  0.7694,  0.2892,  0.1639, -0.4127]],\n",
      "\n",
      "        [[-0.9813,  0.7694,  0.2892,  0.1639, -0.4127]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8639, -0.6578, -0.0422,  0.7143, -1.1111]],\n",
      "\n",
      "        [[-0.8639, -0.6578, -0.0422,  0.7143, -1.1111]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9777,  0.7678,  0.2885,  0.1632, -0.4119]],\n",
      "\n",
      "        [[-0.9777,  0.7678,  0.2885,  0.1632, -0.4119]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8640, -0.6572, -0.0422,  0.7146, -1.1115]],\n",
      "\n",
      "        [[-0.8640, -0.6572, -0.0422,  0.7146, -1.1115]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9735,  0.7658,  0.2876,  0.1625, -0.4109]],\n",
      "\n",
      "        [[-0.9735,  0.7658,  0.2876,  0.1625, -0.4109]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8641, -0.6565, -0.0423,  0.7150, -1.1119]],\n",
      "\n",
      "        [[-0.8641, -0.6565, -0.0423,  0.7150, -1.1119]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9686,  0.7636,  0.2867,  0.1616, -0.4098]],\n",
      "\n",
      "        [[-0.9686,  0.7636,  0.2867,  0.1616, -0.4098]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8642, -0.6558, -0.0424,  0.7154, -1.1123]],\n",
      "\n",
      "        [[-0.8642, -0.6558, -0.0424,  0.7154, -1.1123]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9632,  0.7611,  0.2856,  0.1607, -0.4086]],\n",
      "\n",
      "        [[-0.9632,  0.7611,  0.2856,  0.1607, -0.4086]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8643, -0.6549, -0.0425,  0.7158, -1.1128]],\n",
      "\n",
      "        [[-0.8643, -0.6549, -0.0425,  0.7158, -1.1128]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9573,  0.7584,  0.2844,  0.1596, -0.4072]],\n",
      "\n",
      "        [[-0.9573,  0.7584,  0.2844,  0.1596, -0.4072]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "k tensor([[[-0.8644, -0.6540, -0.0426,  0.7162, -1.1133]],\n",
      "\n",
      "        [[-0.8644, -0.6540, -0.0426,  0.7162, -1.1133]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "v tensor([[[-0.9509,  0.7555,  0.2831,  0.1585, -0.4057]],\n",
      "\n",
      "        [[-0.9509,  0.7555,  0.2831,  0.1585, -0.4057]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "class LongTermMemory(nn.Module):\n",
    "    \"\"\"\n",
    "    This is a key-value neural network memory store.\n",
    "\n",
    "    Retrieve\n",
    "    - query -> output\n",
    "\n",
    "    Update\n",
    "    - key, output -> update\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vector_size: int):\n",
    "        super(LongTermMemory, self).__init__()\n",
    "\n",
    "        self.neural_net = nn.Sequential(\n",
    "            nn.Linear(vector_size, vector_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(vector_size, vector_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(vector_size, vector_size),\n",
    "        )\n",
    "\n",
    "        self.w_q = nn.Linear(vector_size, vector_size)\n",
    "        self.w_k = nn.Linear(vector_size, vector_size)\n",
    "        self.w_v = nn.Linear(vector_size, vector_size)\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            self.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0001\n",
    "        )\n",
    "        ## 결국 SGD에서 momentum과 weight decay를 쓰는건,\n",
    "        ## past surprise 반영과\n",
    "        ## forgetting mechanism 사용하는것과 동일\n",
    "\n",
    "    def retrieve_memory(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        q = self.w_q(seq)\n",
    "        output = self.neural_net(q)\n",
    "        return output\n",
    "\n",
    "    def update_memory(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.enable_grad():\n",
    "            seq = seq.detach()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            k = self.w_k(seq)\n",
    "            v = self.w_v(seq)\n",
    "\n",
    "            print(\"k\", k)\n",
    "            print(\"v\", v)\n",
    "\n",
    "            output = self.neural_net(k)\n",
    "            surprise = torch.norm(output - v, p=2, dim=-1)\n",
    "            surprise = surprise.sum()\n",
    "            surprise.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return self.retrieve_memory(seq)\n",
    "\n",
    "    def forward(self, seq: torch.Tensor, is_update: bool = True) -> torch.Tensor:\n",
    "        if is_update:\n",
    "            return self.update_memory(seq)\n",
    "        else:\n",
    "            return self.retrieve_memory(seq)\n",
    "\n",
    "\n",
    "# def test_structure():\n",
    "memory = LongTermMemory(\n",
    "    vector_size=5,\n",
    ")\n",
    "# torchinfo.summary(memory, input_data=torch.randn(2, 10, 5))\n",
    "seq = torch.ones(2, 1, 5)\n",
    "for i in range(10):\n",
    "    memory.update_memory(seq)\n",
    "\n",
    "print(seq)\n",
    "# test_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistent_memory torch.Size([2, 5, 8])\n",
      "self.rotation_matrix torch.Size([1, 5000, 1, 2, 2, 2])\n",
      "y torch.Size([2, 25, 2, 2, 2, 1])\n",
      "self.rotation_matrix torch.Size([1, 5000, 1, 2, 2, 2])\n",
      "y torch.Size([2, 25, 2, 2, 2, 1])\n",
      "self.rotation_matrix torch.Size([1, 5000, 1, 2, 2, 2])\n",
      "y torch.Size([2, 25, 2, 2, 2, 1])\n",
      "y torch.Size([2, 25, 16])\n",
      "y torch.Size([2, 25, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DecoderBlock                             [2, 10, 8]                40\n",
       "├─LongTermMemory: 1-1                    [2, 10, 8]                144\n",
       "│    └─Linear: 2-1                       [2, 10, 8]                72\n",
       "│    └─Sequential: 2-2                   [2, 10, 8]                --\n",
       "│    │    └─Linear: 3-1                  [2, 10, 8]                72\n",
       "│    │    └─ReLU: 3-2                    [2, 10, 8]                --\n",
       "│    │    └─Linear: 3-3                  [2, 10, 8]                72\n",
       "│    │    └─ReLU: 3-4                    [2, 10, 8]                --\n",
       "│    │    └─Linear: 3-5                  [2, 10, 8]                72\n",
       "├─Linear: 1-2                            [2, 25, 8]                72\n",
       "├─Linear: 1-3                            [2, 25, 8]                72\n",
       "├─Linear: 1-4                            [2, 25, 8]                72\n",
       "├─RotaryPositionalEmbedding: 1-5         [2, 25, 2, 4]             --\n",
       "├─RotaryPositionalEmbedding: 1-6         [2, 25, 2, 4]             --\n",
       "├─RotaryPositionalEmbedding: 1-7         [2, 25, 2, 4]             --\n",
       "├─Linear: 1-8                            [2, 25, 8]                72\n",
       "├─LongTermMemory: 1-9                    [2, 25, 8]                (recursive)\n",
       "│    └─Linear: 2-3                       [2, 25, 8]                (recursive)\n",
       "│    └─Sequential: 2-4                   [2, 25, 8]                (recursive)\n",
       "│    │    └─Linear: 3-6                  [2, 25, 8]                (recursive)\n",
       "│    │    └─ReLU: 3-7                    [2, 25, 8]                --\n",
       "│    │    └─Linear: 3-8                  [2, 25, 8]                (recursive)\n",
       "│    │    └─ReLU: 3-9                    [2, 25, 8]                --\n",
       "│    │    └─Linear: 3-10                 [2, 25, 8]                (recursive)\n",
       "├─Sequential: 1-10                       [2, 25, 8]                --\n",
       "│    └─Linear: 2-5                       [2, 25, 8]                136\n",
       "│    └─ReLU: 2-6                         [2, 25, 8]                --\n",
       "│    └─Linear: 2-7                       [2, 25, 8]                72\n",
       "==========================================================================================\n",
       "Total params: 968\n",
       "Trainable params: 968\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.04\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.04\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_size: int,\n",
    "        num_heads: int,\n",
    "        persistent_memory_length: int,\n",
    "        long_term_memory_length: int,\n",
    "    ):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.persistent_memory = nn.Parameter(\n",
    "            torch.randn(1, persistent_memory_length, vector_size)\n",
    "        )\n",
    "\n",
    "        self.long_term_memory_length = long_term_memory_length\n",
    "        self.long_term_memory = LongTermMemory(vector_size=vector_size)\n",
    "\n",
    "        self.w_q = nn.Linear(vector_size, vector_size)\n",
    "        self.w_k = nn.Linear(vector_size, vector_size)\n",
    "        self.w_v = nn.Linear(vector_size, vector_size)\n",
    "\n",
    "        self.head_size = vector_size // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.positional_encoding = RotaryPositionalEmbedding(\n",
    "            dimension=self.head_size, max_seq_len=5000, theta=10_000\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(vector_size, vector_size)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(2 * vector_size, vector_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(vector_size, vector_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, seq: torch.Tensor) -> torch.Tensor:\n",
    "        ## Get input size\n",
    "        batch, seq_len, vector_size = seq.size()\n",
    "\n",
    "        ## retrieve memories\n",
    "        ## persistent memory: [batch, persistent_memory_length, vector_size]\n",
    "        ## long term memory: [batch, long_term_memory_length, vector_size]\n",
    "        persistent_memory = self.persistent_memory.repeat(batch, 1, 1)\n",
    "        print(\"persistent_memory\", persistent_memory.shape)\n",
    "        long_term_memory = self.long_term_memory(seq, is_update=False)\n",
    "\n",
    "        memory_length = persistent_memory.size(1) + long_term_memory.size(1)\n",
    "\n",
    "        ## concat memories and input\n",
    "        seq = torch.cat([persistent_memory, long_term_memory, seq], dim=-2)\n",
    "\n",
    "        ## q, k, v\n",
    "        q = self.w_q(seq)\n",
    "        k = self.w_k(seq)\n",
    "        v = self.w_v(seq)\n",
    "\n",
    "        ## multi head attention\n",
    "        q = q.view(batch, seq_len + memory_length, self.num_heads, self.head_size)\n",
    "        k = k.view(batch, seq_len + memory_length, self.num_heads, self.head_size)\n",
    "        v = v.view(batch, seq_len + memory_length, self.num_heads, self.head_size)\n",
    "\n",
    "        ## positional encoding\n",
    "        q = self.positional_encoding(q)\n",
    "        k = self.positional_encoding(k)\n",
    "        v = self.positional_encoding(v)\n",
    "\n",
    "        ## transpose for attention\n",
    "        ## => [batch, heads, seq, vec]\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        ## calculate attention\n",
    "        attention = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_size)\n",
    "\n",
    "        mask = torch.zeros_like(attention)\n",
    "        _memory_length = persistent_memory.size(1) + long_term_memory.size(1)\n",
    "        mask[:, :, :_memory_length, :_memory_length] = 1\n",
    "        mask[:, :, _memory_length:, _memory_length:] = torch.triu(\n",
    "            torch.ones_like(mask[:, :, _memory_length:, _memory_length:]), diagonal=1\n",
    "        )\n",
    "\n",
    "        attention = attention.masked_fill(mask == 1, -float(\"inf\"))\n",
    "        attention = torch.softmax(attention, dim=-1)\n",
    "        attention = attention @ v\n",
    "        attention = attention.transpose(1, 2)\n",
    "        attention = attention.contiguous().view(\n",
    "            batch, _memory_length + seq_len, vector_size\n",
    "        )\n",
    "        attention = self.linear(attention)\n",
    "\n",
    "        ## update long term memory\n",
    "        y = self.long_term_memory(attention, is_update=False)\n",
    "\n",
    "        ## ffn\n",
    "        y = torch.cat([y, attention], dim=-1)\n",
    "        print(\"y\", y.shape)\n",
    "        y = self.ffn(y)\n",
    "        print(\"y\", y.shape)\n",
    "\n",
    "        ## reduce\n",
    "        y = y[:, _memory_length:, :]\n",
    "\n",
    "        ## retrieve memory\n",
    "        return y\n",
    "\n",
    "\n",
    "model = DecoderBlock(\n",
    "    vector_size=8, num_heads=2, persistent_memory_length=5, long_term_memory_length=10\n",
    ")\n",
    "\n",
    "torchinfo.summary(model, input_size=(2, 10, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
